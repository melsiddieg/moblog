[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog, a dedicated space where data science, data engineering, and AI meet the complex and fascinating world of healthcare data. Here, I explore the practical and cutting-edge intersections of technologies like R, Python, Apache Arrow, Spark, and various SQL engines (DuckDB, PostgreSQL, Azure SQL Server, and more) with real-world clinical data challenges. Whether it’s structured data extraction from messy EHRs or mapping clinical records into Common Data Models (CDMs) like OMOP, this blog is for practitioners and enthusiasts who care about building scalable, intelligent, and ethical solutions in the healthcare domain.\nI also dive into the evolving space of AI and machine learning in healthcare—especially Retrieval-Augmented Generation (RAG), fine-tuning small language models on domain-specific corpora, and deploying models that respect both data privacy and operational efficiency. From deep dives into Spark-based data pipelines to hands-on tutorials with DuckDB or exploring the nuances of CDM transformations, the content here is designed to balance technical rigor with real-world relevance. Whether you’re a data scientist, engineer, researcher, or just curious about where AI and healthcare data are headed, you’ll find something here to learn, build, and share."
  },
  {
    "objectID": "posts/first-blog/index.html",
    "href": "posts/first-blog/index.html",
    "title": "Demo Blog",
    "section": "",
    "text": "base R plot"
  },
  {
    "objectID": "posts/first-blog/index.html#ploting-in-r",
    "href": "posts/first-blog/index.html#ploting-in-r",
    "title": "Demo Blog",
    "section": "Ploting in R",
    "text": "Ploting in R\nBase R plotting is the original graphics system in R, providing a straightforward and flexible approach to data visualization.\nIt operates on an “artist’s palette” model, where you start with a blank canvas using high-level functions like plot() to create the initial plot, and then incrementally add elements such as points, lines, and text with low-level functions like points(), lines(), and text() .\nThis layered approach allows for detailed customization of plots, enabling users to adjust various aspects such as axes, labels, colors, and symbols to suit their specific needs . While base R plotting may require more manual adjustments compared to newer systems like ggplot2, it remains a powerful tool for creating a wide range of static graphics, from simple scatter plots to complex multi-panel figures\n\nx &lt;- 1:50\ny &lt;- x^2\nplot(x,y,col='darkgreen',pch=20)"
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html",
    "href": "posts/linux-agentic-desktop/index.html",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "",
    "text": "For decades, the open-source world has asked: “Is this finally the year of the Linux desktop?” For actual humans, the answer always seemed to be “not quite”—until now. The catch? Linux desktops have finally conquered the world… but as the home turf of AI agents, not people.\nYes, in the age of superagents—digital workers like OpenAI’s Agent Mode, Manus, TARS, and more—the Linux desktop is having its victory lap. It’s just that the new users don’t need a mouse, a coffee, or a standing desk. They’re AI, and they’ve found their perfect desktop home."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-linux-paradox-invisible-power-visible-absence",
    "href": "posts/linux-agentic-desktop/index.html#the-linux-paradox-invisible-power-visible-absence",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Linux Paradox: Invisible Power, Visible Absence",
    "text": "The Linux Paradox: Invisible Power, Visible Absence\nTo understand why this is such a plot twist, you need to appreciate the paradox of Linux: it is everywhere and nowhere.\n\nLinux is the invisible backbone of the internet: It runs the majority of the world’s servers, powers almost every major website, and forms the core of cloud giants like AWS, Google Cloud, and Azure.\nSupercomputing? It’s Linux. Over 95% of the world’s fastest supercomputers run on Linux.\nThe Cloud? Linux runs the show. Most virtual machines spun up in the cloud are Linux. When companies deploy at scale, it’s always Linux under the hood.\nYour phone? That’s Linux, too. Android, the world’s most popular mobile OS, is built on the Linux kernel.\n\nBut despite dominating everywhere else, Linux has always been the underdog on the personal desktop. Windows reigns supreme in homes, schools, and businesses. macOS has its loyal fanbase. For the average computer user, the “Linux desktop” is barely visible—unless you’re a developer, a sysadmin, or an academic."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-dream-deferred-waiting-for-the-year-of-the-linux-desktop",
    "href": "posts/linux-agentic-desktop/index.html#the-dream-deferred-waiting-for-the-year-of-the-linux-desktop",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Dream Deferred: Waiting for the Year of the Linux Desktop",
    "text": "The Dream Deferred: Waiting for the Year of the Linux Desktop\nAsk any Linux enthusiast: The “Year of the Linux Desktop” is practically a meme.\n\nFor 25+ years, advocates believed that any day now, Linux would become the OS of choice for everyone—more stable, more secure, more customizable.\nIn reality? Despite huge popularity with developers, hackers, and researchers—and legendary status in universities—Linux never quite broke through with the masses.\nMainstream adoption always seemed just out of reach, blocked by hardware compatibility, proprietary software, gaming, and the inertia of the Windows world.\n\nYet the dream never died. Conferences, blogs, and podcasts would regularly ask: “Is this finally the year?” The answer, year after year, was “not quite.”"
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#why-ai-agents-choose-linux-and-why-proprietary-oses-are-left-behind",
    "href": "posts/linux-agentic-desktop/index.html#why-ai-agents-choose-linux-and-why-proprietary-oses-are-left-behind",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "Why AI Agents Choose Linux (And Why Proprietary OSes Are Left Behind)",
    "text": "Why AI Agents Choose Linux (And Why Proprietary OSes Are Left Behind)\nThe reason for this shift isn’t just hype, or tradition, or even ideology. It comes down to fundamental technical and economic advantages:\n\n1. Open Source, Open World\n\nNo licensing fees. No legal headaches. Linux is free at any scale. Spin up 10,000 desktops for agents in the cloud? Nobody’s sending you a bill.\nHackable by design: Agents (and their creators) can inspect, modify, or automate any part of the stack, from kernel to GUI. Proprietary OSes simply can’t compete here.\nInfinite extensibility: If a tool or feature doesn’t exist, you can build it—or the agent can.\n\n\n\n2. Cloud Supremacy\n\nLinux dominates the cloud. Every major cloud provider (AWS, GCP, Azure) is optimized for Linux VMs, containers, and orchestration.\nNeed to instantly deploy isolated, secure desktops for thousands of agents? Linux is already the backbone.\nNo OS is as “cloud native” as Linux. Licensing for Windows VMs is slow, costly, and restrictive. macOS is barely available outside Apple’s hardware.\n\n\n\n3. Customizability, Speed, and Lean Performance\n\nUltra-customizable: Want a barebones, lightning-fast desktop that boots in seconds and only runs what you need? Linux is built for that.\nNo bloat: Agents don’t care for Cortana, Siri, or animated emojis. Linux offers minimalism and raw speed.\nFast to spin, low latency: The agentic revolution depends on spinning up and tearing down environments in milliseconds. Linux delivers this with tiny disk images, lean memory profiles, and true headless operation.\n\n\n\n4. Proven Automation & Scriptability\n\nAutomation is native: Agents can automate GUIs, file systems, networking, and even the kernel itself, using decades-old, battle-tested scripting and API frameworks.\nStable accessibility layers and automation tools: From DBus to ATK, everything’s accessible, scriptable, and open."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-rise-of-ai-ready-linux-distros-the-agentic-os-revolution",
    "href": "posts/linux-agentic-desktop/index.html#the-rise-of-ai-ready-linux-distros-the-agentic-os-revolution",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Rise of AI-Ready Linux Distros: The Agentic OS Revolution",
    "text": "The Rise of AI-Ready Linux Distros: The Agentic OS Revolution\nThe landscape is evolving so quickly that now specialized Linux distributions are being purpose-built for AI agents themselves—ushering in a new era of the “Agentic OS”.\n\n\nArchon OS is a leading example: an ultra-lean, AI-native Linux distribution designed from the ground up for agentic use. Archon OS boots in seconds, offers tightly sandboxed environments, and comes pre-equipped with all the APIs and automation tools that superagents demand—no onboarding, no distractions, no bloat.\n\nIt’s not about user-friendliness; it’s about agent-efficiency.\nWith secure, ephemeral sandboxes, these distros enable agents to safely spawn, destroy, and scale their own workspaces—hundreds or thousands at a time.\n\nOther spins and projects are following: headless Ubuntu, container-native Debian, cloud-tuned agent images, and more.\nThese new “Agent OSes” are optimized not for human workflows, but for machine-to-machine automation and agentic orchestration.\n\n\nJust as Ubuntu and Mint made Linux friendlier for people, Archon OS and its siblings are making Linux frictionless for AI agents. The Agentic OS genre has officially arrived."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-rise-of-superagents-manus-tars-and-beyond",
    "href": "posts/linux-agentic-desktop/index.html#the-rise-of-superagents-manus-tars-and-beyond",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Rise of Superagents: Manus, TARS, and Beyond",
    "text": "The Rise of Superagents: Manus, TARS, and Beyond\n2025 isn’t the year of the human Linux desktop. It’s the year of the agentic Linux desktop—the cloud-powered sandbox where AI agents thrive.\n\nWho are these new digital power-users?\n\nOpenAI Agent Mode / Operator\nRuns its own Linux desktop-in-the-cloud, controlling Chrome, LibreOffice, files, and more. Completes multi-step tasks like downloading, editing, and moving documents with no human clicks required.\n\n\nAnthropic’s Claude with Computer Use\nUses Linux sandboxes for visual and API-driven automation, with full access to manipulate GUIs and files.\n\n\nManus.im\nAn open-source, agentic “operating system” for AI agents. Manus spins up dedicated Linux environments so any LLM can automate apps, run workflows, and interact with real software—at scale and at speed.\n\n\nTARS\nA generalist superagent inspired by sci-fi, TARS runs in containerized Linux desktops, mastering browsers, spreadsheets, and even legacy apps, all within secure, reproducible Linux VMs.\n\n\nOther Players & Ecosystem Tools\n\nScreenEnv: Open-source project building virtual Ubuntu desktops for AI agent testing, safely and at scale.\nLinux Foundation Agent Gateway: Building standards for cross-agent, cross-app Linux integration.\nAcademic Projects (ComputerRL, SchedCP): Advancing agentic automation and reinforcement learning inside Linux GUIs and systems."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#what-does-this-mean-for-desktop-apps-on-linux",
    "href": "posts/linux-agentic-desktop/index.html#what-does-this-mean-for-desktop-apps-on-linux",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "What Does This Mean for Desktop Apps on Linux?",
    "text": "What Does This Mean for Desktop Apps on Linux?\nIf you make desktop software for Linux, your most active users soon may not be people, but agents.\n\nA New Kind of “User”:\n\nAutomation is king: Agents demand robust APIs, headless modes, and stable scripting. If your app can’t be reliably automated, it will be left behind.\nAccessibility and stability matter: UI elements must be predictable and well-exposed. Fragile GUI automation is a dealbreaker.\nSecurity and sandboxing: Agents need just enough access, never more. Fine-grained permissions and logs are now basic hygiene.\nNative support is a must: Apps with flaky Linux ports will be abandoned for native alternatives, or for open-source clones.\n\n\n\nUX for Agents (Not Humans):\n\nApps may expose semantic, task-based APIs (“generate a report from these files”) instead of just GUI-driven interfaces.\nLogging, feedback, and “undo” support will be crucial for auditing and safety.\n\n\n\nThe App Developer’s Dilemma:\n\nHow do you test your app for agents? Start thinking about CI pipelines where your “user” is an AI agent running inside a Linux sandbox!"
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-surprise-boon-for-linux-apps-libreoffice-gimp-inkscape-beyond",
    "href": "posts/linux-agentic-desktop/index.html#the-surprise-boon-for-linux-apps-libreoffice-gimp-inkscape-beyond",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Surprise Boon for Linux Apps: LibreOffice, GIMP, Inkscape & Beyond",
    "text": "The Surprise Boon for Linux Apps: LibreOffice, GIMP, Inkscape & Beyond\nIronically, the new era of agentic Linux desktops could be the best thing that’s ever happened to open source desktop apps.\n\n\nLibreOffice is now being used by agents as a workhorse for document generation, editing, and automation at unprecedented scale—not just by humans writing essays, but by superagents assembling reports, forms, and knowledge bases around the clock.\n\nEvery day, LibreOffice Writer, Calc, and Impress are being driven to their limits, automating tasks faster and at greater volume than most human users ever could.\nAgents’ demands are relentless and uncompromising. Even minor bugs, clunky behaviors, or slow performance become immediate bottlenecks at scale—forcing rapid iteration, bugfixes, and quality improvements.\n\nOther Linux apps, too—like Inkscape, GIMP, and countless writing and workflow tools—are getting a second life.\n\nAgents use GIMP and Inkscape for image generation, conversion, and batch-editing; text tools for automated content creation and formatting.\nTools that may have lagged behind their proprietary Windows/macOS counterparts are now being “battle-tested” by AI. The “good enough” bar is rising—agents are discovering edge cases, pushing APIs, and exposing bugs that would otherwise stay hidden.\nAs agents become power users, open source app developers are gaining new telemetry, feedback, and bug reports at a rate never seen before.\n\n\n\nWhat does this mean? The “AI desktop” could spark an unprecedented renaissance for Linux desktop apps. With agents pushing, breaking, and improving these tools at scale, we may finally see LibreOffice, GIMP, Inkscape and other stalwarts close the gap with (or even leapfrog) proprietary software—not for human polish, but for raw reliability, scriptability, and automation."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#why-not-windows-or-mac",
    "href": "posts/linux-agentic-desktop/index.html#why-not-windows-or-mac",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "Why Not Windows or Mac?",
    "text": "Why Not Windows or Mac?\nThe short version:\n\nWindows and macOS are locked-down, expensive, and bloated.\nLicense fees, restrictive virtualization, slow boot times, proprietary protocols, and unpredictable updates all stand in the way of agentic automation.\nThe cloud isn’t optimized for them, and neither are AI workflows.\n\nAgents don’t want branding—they want freedom and speed."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-future-the-decade-of-the-agentic-linux-desktop",
    "href": "posts/linux-agentic-desktop/index.html#the-future-the-decade-of-the-agentic-linux-desktop",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Future: The Decade of the Agentic Linux Desktop",
    "text": "The Future: The Decade of the Agentic Linux Desktop\nFrom 2025 onward, expect:\n\nAgent-aware apps: Major Linux software will ship “agent mode” APIs and automation docs.\nStandardized agent protocols: Open standards (like Model Context Protocol) will make agentic workflows cross-app and cross-platform.\nZero-trust security: Granular sandboxing and permissioning for all agent activities.\nAgent dashboards: Linux desktops will include visual management tools for agent workflows and activity logs.\nA new breed of distros: AI-ready, agent-optimized Linux OSes like Archon OS will become the “default” for cloud and automation-driven agent infrastructure."
  },
  {
    "objectID": "posts/linux-agentic-desktop/index.html#the-year-of-the-linux-desktop-has-arrived-for-ai",
    "href": "posts/linux-agentic-desktop/index.html#the-year-of-the-linux-desktop-has-arrived-for-ai",
    "title": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!",
    "section": "The Year of the Linux Desktop Has Arrived… For AI",
    "text": "The Year of the Linux Desktop Has Arrived… For AI\nSo, after decades of waiting, the Linux desktop finally wins—but not in the way anyone predicted. The new power-users are silent, fast, and relentless. They don’t need themes or wallpapers. They need access, speed, and infinite customization. And that’s exactly what Linux delivers.\nFor humans, the “year of the Linux desktop” is a meme. For AI agents—and for the distros being built just for them—it’s already a reality.\nWant a deep dive on Archon OS, developer tips for agentic app design, or a launch thread? Let me know! This is only the beginning."
  },
  {
    "objectID": "posts/efficient-data-r/index.html#the-power-of-efficient-file-formats-and-partitioning",
    "href": "posts/efficient-data-r/index.html#the-power-of-efficient-file-formats-and-partitioning",
    "title": "Efficient Data wrangling in R",
    "section": "The Power of Efficient File Formats and Partitioning",
    "text": "The Power of Efficient File Formats and Partitioning\nBefore diving into specific tools, it’s crucial to understand the importance of efficient file formats and data partitioning.\n\nParquet: The Champion of Big Data\nParquet has become the go-to file format for big data analytics, and for good reason. It’s a columnar storage format that offers excellent compression and supports predicate pushdown, allowing for efficient querying of large datasets. When working with big data in R, converting your data to Parquet can lead to significant performance improvements.\n\n\nPartitioning: Divide and Conquer\nPartitioning is a technique that divides large datasets into smaller, more manageable chunks. This approach enables parallel processing and efficient querying. A common partitioning strategy is to split data by date, creating a directory structure like /year=2023/month=06/data.parquet. This allows you to quickly filter data based on time periods without scanning the entire dataset.\nHere’s a quick example of how you can convert a large CSV file to partitioned Parquet using the Arrow package in R:\nlibrary(arrow)\nlibrary(dplyr)\n\n# Read CSV file\ncsv_dataset &lt;- open_dataset(\"large_dataset.csv\", format = \"csv\")\n\n# Define partitioning schema and write to partitioned Parquet\nwrite_dataset(csv_dataset, \n              \"partitioned_dataset\",\n              format = \"parquet\",\n              partitioning = schema(year = int32(), month = int32()))\nThis code reads a large CSV file and writes it as a partitioned Parquet dataset, organized by year and month."
  },
  {
    "objectID": "posts/efficient-data-r/index.html#arrow-the-swiss-army-knife-of-big-data",
    "href": "posts/efficient-data-r/index.html#arrow-the-swiss-army-knife-of-big-data",
    "title": "Efficient Data wrangling in R",
    "section": "Arrow: The Swiss Army Knife of Big Data",
    "text": "Arrow: The Swiss Army Knife of Big Data\nApache Arrow is a cross-language development platform for in-memory data, providing a standardized columnar memory format. The Arrow package in R brings this power to the R ecosystem.\n\nKey Features of Arrow:\n\nMemory Mapping: Allows efficient access to data without loading entire datasets into memory.\nSIMD Operations: Utilizes CPU’s Single Instruction, Multiple Data capabilities for faster processing.\nStreaming Execution: Processes data in chunks, reducing memory footprint.\nHere’s an example of using Arrow to efficiently query a partitioned Parquet dataset:\n\nlibrary(arrow)\n\n# Open partitioned dataset\ndataset &lt;- open_dataset(\"partitioned_dataset\", format = \"parquet\")\n\n# Efficient querying with partition and predicate pushdown\nresult &lt;- dataset %&gt;%\n  filter(year == 2023, month == 6) %&gt;%\n  select(col1, col2) %&gt;%\n  collect()\nThis query leverages both partition pruning and predicate pushdown, ensuring that only the necessary data is read and processed."
  },
  {
    "objectID": "posts/efficient-data-r/index.html#polars-speed-and-efficiency-in-r",
    "href": "posts/efficient-data-r/index.html#polars-speed-and-efficiency-in-r",
    "title": "Efficient Data wrangling in R",
    "section": "Polars: Speed and Efficiency in R",
    "text": "Polars: Speed and Efficiency in R\nPolars is a lightning-fast DataFrames library implemented in Rust, with bindings available for R. It offers both eager and lazy execution modes, providing flexibility and performance.\n\nPolars Lazy Execution:\nPolars’ lazy execution mode allows for query optimization, potentially leading to significant performance improvements. Here’s an example:\nlibrary(polars)\n\n# Create a lazy DataFrame with streaming enabled\nlazy_df &lt;- pl$lazy_csv_reader(\"large_dataset.csv\", rechunk = FALSE)\n\n# Define operations\nresult &lt;- lazy_df$\n  select(pl$col(\"col1\"), pl$col(\"col2\"))$\n  filter(pl$col(\"col1\") &gt; 100)$\n  group_by(\"col2\")$\n  agg(pl$col(\"col1\")$mean())$\n  collect(streaming = TRUE)\nIn this example, Polars optimizes the query plan and uses streaming execution to efficiently process the data."
  },
  {
    "objectID": "posts/efficient-data-r/index.html#duckdb-sql-power-for-local-data",
    "href": "posts/efficient-data-r/index.html#duckdb-sql-power-for-local-data",
    "title": "Efficient Data wrangling in R",
    "section": "DuckDB: SQL Power for Local Data",
    "text": "DuckDB: SQL Power for Local Data\nDuckDB brings the power of a columnar-oriented SQL database to local, serverless environments. It’s particularly well-suited for analytical queries on large datasets.\n\nDuckDB’s Efficiency:\nDuckDB optimizes for the entire memory hierarchy, from CPU cache to disk. It uses techniques like vectorized execution and adaptive algorithms to process data efficiently. Here’s an example of using DuckDB to query a partitioned Parquet dataset:\nlibrary(duckdb)\nlibrary(dplyr)\n\ncon &lt;- dbConnect(duckdb())\nresult &lt;- tbl(con, \"parquet_scan('partitioned_dataset/**/*.parquet', \n                                 hive_partitioning=1)\") %&gt;%\n  filter(year == 2023, month == 6) %&gt;%\n  select(col1, col2) %&gt;%\n  collect()\n\ndbDisconnect(con, shutdown = TRUE)\nDuckDB automatically detects the partitioning scheme and uses it for efficient data skipping."
  },
  {
    "objectID": "posts/efficient-data-r/index.html#the-importance-of-operation-order",
    "href": "posts/efficient-data-r/index.html#the-importance-of-operation-order",
    "title": "Efficient Data wrangling in R",
    "section": "The Importance of Operation Order",
    "text": "The Importance of Operation Order\nWhen working with large datasets, the order of operations can significantly impact performance, especially in eager evaluation systems. Consider this example using dplyr:\n# Less efficient\ndf %&gt;%\n  group_by(category) %&gt;%\n  filter(value &gt; 100) %&gt;%\n  summarise(mean_value = mean(value))\n\n# More efficient\ndf %&gt;%\n  filter(value &gt; 100) %&gt;%\n  group_by(category) %&gt;%\n  summarise(mean_value = mean(value))\nIn general, it’s more efficient to filter data before grouping. However, lazy evaluation systems like Polars lazy and DuckDB can often optimize the query plan regardless of the order you specify operations."
  },
  {
    "objectID": "posts/efficient-data-r/index.html#summary-choosing-the-right-tool",
    "href": "posts/efficient-data-r/index.html#summary-choosing-the-right-tool",
    "title": "Efficient Data wrangling in R",
    "section": "Summary: Choosing the Right Tool",
    "text": "Summary: Choosing the Right Tool\nArrow, Polars, and DuckDB each offer unique strengths for handling large datasets in R:\n\nArrow excels in memory mapping and SIMD operations.\nPolars shines with its lazy evaluation and query optimization.\nDuckDB stands out for its adaptive algorithms and SQL engine"
  },
  {
    "objectID": "posts/efficient-data-r/index.html#takeaways-and-best-practices",
    "href": "posts/efficient-data-r/index.html#takeaways-and-best-practices",
    "title": "Efficient Data wrangling in R",
    "section": "Takeaways and Best Practices",
    "text": "Takeaways and Best Practices\nWhen working with large datasets in R, consider these best practices:\n\nUse partitioned Parquet for storing large datasets.\nLeverage streaming capabilities to reduce memory footprint.\nUtilize automatic chunking and batch processing when available.\nChoose partitioning schemes that align with common query patterns.\nBenchmark different approaches for your specific use case.\nPay attention to the order of operations, especially in eager evaluation systems\n\nBy employing these advanced techniques and tools, R users can efficiently handle datasets that were once considered too large for local processing. As the R ecosystem continues to evolve, we can expect even more powerful and efficient data handling capabilities in the future.\nHappy data crunching!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A blog about Data Science, Data Engineering, AI, and Healthcare Data Management",
    "section": "",
    "text": "The Year of the Linux Desktop Is Finally Here — But Not for Humans!\n\n\n\nlinux\n\nai\n\nagents\n\nopen-source\n\n\n\n\n\n\n\n\n\nDec 8, 2025\n\n\nMohammed Abdallah\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Data wrangling in R\n\n\n\nbig data\n\nR\n\npolars\n\nduckdb\n\napache arrow\n\n\n\n\n\n\n\n\n\nApr 5, 2025\n\n\nMohammed Abdallah\n\n\n\n\n\n\n\n\n\n\n\n\nDemo Blog\n\n\n\nR\n\nVisualizaion\n\n\n\n\n\n\n\n\n\nApr 1, 2025\n\n\nMohammed Abdallah\n\n\n\n\n\nNo matching items"
  }
]